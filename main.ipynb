{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of mobile robotics [MICRO-452]  \n",
    "## Project report, EPFL Robotic Master, 12.12.21\n",
    "\n",
    "<img src=\"image/logo-epfl.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Author: **Nour Tnani [296442], Xavier Nal [288275], Alicia Mauroux [274618], Antoine Perrin [283652]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "Our project is to find a parking spot to our Thymio and to guide it to this spot using Global Navigation. We imagined it in a whole city like in this figure:\n",
    "<img src=\"image/map_multi.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "But for this project, we focused only on a part of the map like you can see in the figure2. Thymio will evolve on this map where there are two houses and four parking spots. Three of these spots will be occupied and only one of them will be free. There will be some \"dumb\" Thymio that will evolve in this map too, and our Thymio will have to avoid them, using Local Navigation. \n",
    "\n",
    "Here is our map:\n",
    "\n",
    "Figure2: Green = parking spots, Blue = obstacles, Black = \"dumb\" Thymio's path\n",
    "<img src=\"image/map.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "For this project, we chose to cut the work in 4 parts:\n",
    "- **Computer Vision and Kalman Filter** [Filtering + Vision]\n",
    "- **Map initialisation and optimal path calculation** [Global Navigation]\n",
    "- **Following the logical path** [Motion Control]\n",
    "- **Local Navigation and Implementation of the \"Dumb\" Thymio** [Local Navigation]\n",
    "\n",
    "We worked individually on these parts and then progressively added one part with another. When we were satisfied with the result, we could move on and add another part, and so on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theoretical explanation\n",
    "This part will explain how we implemented our idea of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Computer vision and Kalman filter\n",
    "\n",
    "The camera allows us to do computer vision. We use it to manage the global navigation. The camera gives us the image which is 3 array where we have all the pixel of the map in the RGB color. We will apply some mask to extract differents objects of the image. There are three different object in the map: the robot, the building and the parking slot. Each objects has a differents color that we use to identified them. \n",
    "\n",
    "The detection of the color was coded with the library opencv. For starting point for the detection ( and kalman filter) we used files from the youtube channel L42Project ( the github repository is https://github.com/L42Project/Tutoriels/tree/master/Divers/tutoriel36 ). The"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Map initialisation and optimal path calculation\n",
    "\n",
    "In this part we will see how we set and use the map to compute the optimal path that the robot has to follow to arrive on a free parking slot.\n",
    "\n",
    "Type of path calculation : We choose to implement the A* algorithm that we have see during the course and the exercices.\n",
    "In order to do that, we had to transform the frame that the camera give us to a grid of desired lenght.\n",
    "We then speek of square by side and no more pixel by side. \n",
    "We choose the square by side to have a good precision but a low cost of calculation. Therefore we have to deal between thoses too parameters. After some testing we choose avalue of 50 squares for the smallest side. That give us  \n",
    "Those are the steps that we applied on the frame to obtain a final squared wanted grid with the obstacles in it : \n",
    "- Take the frame\n",
    "<img src=\"image/frame.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "- Extract the obstacle from a mask to see only the bleue(the obstacle) --> implemented by the vision part\n",
    "<img src=\"image/masque1.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"image/masque2.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "- Expand the obstacle on the mask grid. To add a security and avoid the robot collapsing with the obstacle\n",
    "<img src=\"image/secured.jpg\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "- Resize the expand mask grid to have a wanted squared dimention and no more pixels dimention. This is the final grid.\n",
    "<img src=\"image/rezize.jpg\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "- Compute the optimal path from the A* algorithm.\n",
    "<img src=\"image/TOTAL.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "We run this \"initialisation\" one time before the \"runing\" loop to avoid useless recomputation of the path each time.\n",
    "\n",
    "Once the optimal path has been compute, we defined the current goal as the next path point until we are on the final goal. We then have implemented a fonction to update the current goal to send to the control and movement part (see 1.3). \n",
    "Now the robot just have to follow the updated current goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Robot control and path following \n",
    "\n",
    "\n",
    "The function takes continuously as parameters the position of the robot and its angle which are given by the Vision module. The angle is in the range of [-pi, pi]. It also takes as parameters the continuously updated goals that are given by the Optimal Path module.\n",
    "\n",
    "We implement a function that computes the error in position (which is the distance between the goal and the robot) and the error in angle (We are inspired by the function described in https://stackoverflow.com/questions/2827393/angles-between-two-n-dimensional-vectors-in-python to determine the angle of the goal. We changed it to be optimal to the variation we want from the robot (all explained in the comments)).\n",
    "\n",
    "As the angle is computed as a difference between the goal and the robot, if it's positif, then the robot should turn to the left, and if it's negatif, it should turn to the right, which is why we substract the angular error from the right motor speed, and add it to the left motor speed. \n",
    "\n",
    "In a more general way, the function \"move_to_position\" implements a PD (Proportionnal Derivative Controller), by adding a certain speed computed via the remaining distance (multiplied by an experimental coefficient) and adding/substracting an angular speed (multiplied by another experimental coefficient) to the motor's speed. These are added to some basic speed, because otherwise the speed of the robot will be almost zero when it reaches the updated goals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Local navigation and \"Dumb\" robot implementation\n",
    "We use the local navigation in order to avoid the other cars of the \"city\". Those other cars are the \"dumb\" Thymio in this project. Our principle is the following:\n",
    "<img src=\"image/MAIN_LN.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "We chose to make our Thymio go a little bit wider in order to let the \"Dumb\" Thymio leaves without any collision. \n",
    "\n",
    "**We disable this avoid functionality when we are soon arrived to the parking place** in order to make the parking maneuvers easier for Thymio. \n",
    "\n",
    "The implementation of the avoid function was inspired by the exercices of the course from the week 4. It means that we used the principle that when the robot \"sees\" an object in front of it, we accelerate the weels near this obstacle. We don't use the external horizontal sensors because we would like to be able to follow walls. However, we use them to compute the value of the speed when there's an object detected. It allow us to be more precise (regarding our tests). As we don't want to see the walls to early (otherwise we could not follow the optimal path without interupting it all the time) we avoid obstacles at a very short distance. To be able to do that, we turn on the same spot and not \"smoothly\" like in the exercices. \n",
    "\n",
    "Also, we saved in a global variable if the robot saw an object to the right or to the left. The main reason is to help Thymio to turn back if it is bloqued. The other reason is that it makes our turns more clean when there's an object in one side if we turn on the same spot even is the left obstacle is far.\n",
    "\n",
    "We also computed differently our speed if there was an obstacle only in front of Thymio (otherwise it would turn very large and would often crash into the object). We kept the principle to compute the speed regarding the sensors values in order to give a smoother change of speed. \n",
    "\n",
    "In order to check if there's no more obstacles in Thymio's way, we are checking the front and the two interior side sensors but not the external side ones in case we would be along a wall. \n",
    "\n",
    "About the \"dumb\" robot implementation, it is developped in a different section below as we thought it was more logical that way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Step by step Code\n",
    "To launch all the project, go in in section 3\n",
    "### 2.1 Connection to Thymio and libraries\n",
    "The next cells import all the libraries and the other folders that we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.core.fromnumeric import size\n",
    "from matplotlib import colors\n",
    "\n",
    "# Our files\n",
    "import optimal_path as op\n",
    "from robot import Robot\n",
    "from Map import Map\n",
    "from Local_navigation import* \n",
    "from Mouvement import*\n",
    "from vision import* \n",
    "from optimal_path import* \n",
    "from KalmanFilter import KalmanFilter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Useful functions\n",
    "Functions in order to use Thymio's actuators and sensors easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motors(l_speed=500, r_speed=500, verbose=False):\n",
    "    \"\"\"\n",
    "    Sets the motor speeds of the Thymio \n",
    "    param l_speed: left motor speed\n",
    "    param r_speed: right motor speed\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "    global motor_left_target, motor_right_target\n",
    "    # Printing the speeds if requested\n",
    "    if verbose:\n",
    "        print(\"\\t\\t Setting speed : \", l_speed, r_speed)\n",
    "    motor_left_target = l_speed\n",
    "    motor_right_target = r_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxi():\n",
    "    \"\"\"\n",
    "    Returns the proximity values of the Thymio \n",
    "    \"\"\"\n",
    "    global prox_horizontal\n",
    "    return prox_horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Initialisation\n",
    "\n",
    "\n",
    "In this part we initialise all the values, object, element that we are going to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Init the different object : \n",
    "- The Robot\n",
    "- The Map\n",
    "- The Kalman filter\n",
    "\n",
    "We first initialise the parameter that will be usefull for the overall code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lenght = 1\n",
    "nb_of_square_by_side = 50\n",
    "current = 1\n",
    "\n",
    "global move \n",
    "move = False #bool which indicate how our robot is moving (1: avoid an object VS 0: following the optimal path)\n",
    "kalman_bool = False\n",
    "old_distance = 0\n",
    "old_angle = 0\n",
    "soon_arrived = False\n",
    "thresh_indentation = 15\n",
    "\n",
    "# Object initialisation\n",
    "George = Robot()\n",
    "# nb_of_square_by_side is the nb square that we want regarding y\n",
    "Lausanne = Map(map_lenght, nb_of_square_by_side)\n",
    "KF=KalmanFilter(0.1, [0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Start the camera and take the original frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoCap=cv2.VideoCapture(0)\n",
    "\n",
    "# Take the frame nb \"nb_frame_to_take\":\n",
    "nb_frame_to_take = 10\n",
    "\n",
    "for i in range (nb_frame_to_take): \n",
    "    ret, frame = VideoCap.read()\n",
    "    \n",
    "print(\"frame size\", frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Map initialisation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MAP INITIALISATION\")\n",
    "# Set the map lenght and the pourcentage value between the nb of pixel and nb of square by side:\n",
    "Lausanne.set_map_lenght(frame)\n",
    "\n",
    "# Set the robot goal:\n",
    "goal = init_goal(frame, Lausanne.get_pourcentage())\n",
    "\n",
    "# pre Set the robot pos:\n",
    "pos_robot = (-1,-1)\n",
    "George.set_pos(pos_robot) \n",
    "\n",
    "# Set the robot position and angle with the x axis:\n",
    "pos_robot, angle = update(frame, Lausanne.get_pourcentage())\n",
    "George.set_angle(angle)\n",
    "George.set_goal(goal)\n",
    "George.set_start_pos(pos_robot)\n",
    "George.set_pos(pos_robot)\n",
    "\n",
    "\"\"\"   #A TESTER\n",
    "#Utiliser au cas où il ne trouve pas la bonne position du premier coup\n",
    "while (pos_robot[0] <= 0) & (pos_robot[1] <= 0):\n",
    "    #ret, frame=VideoCap.read()\n",
    "    #display(frame,1,0,0)\n",
    "    ret, frame=VideoCap.read()\n",
    "    #vs.display (frame, 0, 1, 1, 0, 5, Lausanne.get_pourcentage())\n",
    "    pos_robot, angle = update(frame, Lausanne.get_pourcentage())  # fonction qui retourne la position angle etc....\n",
    "    #print(\"Waiting robot position\") \n",
    "\"\"\"\n",
    "\n",
    "print (\"goal\", goal)\n",
    "print (\"start position\", pos_robot)\n",
    "\n",
    "\n",
    "print(\"  - Grid initialisation\")\n",
    "# Extract the Bleu and green of the image for the grid initialisation:\n",
    "mask_bleu, mask_green = mask_map_init(frame)\n",
    "\n",
    "# initialise the map grid with the 2 previous masks:\n",
    "Lausanne.init_grid(mask_bleu,mask_green)\n",
    "grid = Lausanne.get_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Path computation\n",
    "\n",
    "Here we compute the optimal path and save the values in the robot object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMAL PATH: Compute the optimal path from the grid, robot position and goal:\n",
    "print(\"PATH COMPUTATION\")\n",
    "path, visitedNodes = op.path_computation(George.get_start() , George.get_goal() , Lausanne.get_lenght(), grid)\n",
    "\n",
    "George.set_path(path) \n",
    "George.set_visit_nodes(visitedNodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Initialisation's display\n",
    "\n",
    "Here we desplay the initialised map and optimal path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the optimal path\n",
    "op.display_map(Lausanne.get_lenght(),  grid,  George.get_visit_nodes(), George.get_path(), George.get_start(), George.get_goal())\n",
    "\n",
    "# Display the optimal path on the original frame\n",
    "display (frame, 0, 1, 1, 1, George.get_path(), Lausanne.get_pourcentage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Main loop\n",
    "\n",
    "This is the main loop that update the position of the robot and make him move. This section work as follow:\n",
    "\n",
    "- Update the position and angle from the camera\n",
    "- Use Kalman filter to return predicted path\n",
    "- Check if the robot is on the goal\n",
    "- Check if there is an obstacle\n",
    "        - If yes, avoid it\n",
    "        - If no, follow the optimal path\n",
    "- Display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "while start\n",
      "position 0 0 0\n",
      "0 0\n",
      "debut 0 0 0\n",
      "dist_debut 302.89932320822373\n",
      "v 605.7986464164475\n",
      "w 41.803931990020935\n",
      "speed, 41 -41\n",
      "41 -41\n",
      "position 0 0 0\n",
      "0 0\n",
      "debut 0 0 0\n",
      "dist_debut 302.89932320822373\n",
      "v 605.7986464164475\n",
      "w 41.803931990020935\n",
      "speed, 41 -41\n",
      "41 -41\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 1: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26540/2625117252.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mmotors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeed_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspeed_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m#led_arrivé\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\repl.py\u001b[0m in \u001b[0;36msleep\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;31m# wait\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mClientAsync\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;31m# fetch all variables which might be used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\clientasync.py\u001b[0m in \u001b[0;36maw\u001b[1;34m(co)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mClientAsync\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_async_program\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\clientasync.py\u001b[0m in \u001b[0;36mrun_async_program\u001b[1;34m(prog)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0mco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\clientasync.py\u001b[0m in \u001b[0;36mprog\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mnonlocal\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mClientAsync\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_async_program\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\clientasync.py\u001b[0m in \u001b[0;36msleep\u001b[1;34m(self, duration, wake)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mduration\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_waiting_messages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             sleep(self.DEFAULT_SLEEP\n\u001b[0;32m     44\u001b[0m                   \u001b[1;32mif\u001b[0m \u001b[0mduration\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\client.py\u001b[0m in \u001b[0;36mprocess_waiting_messages\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"recv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                 \u001b[0mat_least_one\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mat_least_one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\thymio.py\u001b[0m in \u001b[0;36mprocess_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mfb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mfb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mThymioFB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCHEMA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m             \u001b[0mfb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\fb.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, encoded_fb, schema)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m\"TU\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unexpected schema\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatBuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_fb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\fb.py\u001b[0m in \u001b[0;36mparse_value\u001b[1;34m(encoded_fb, pos, schema)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvtable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[0mpos_field\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                 union_value = FlatBuffer.parse_value(encoded_fb,\n\u001b[0m\u001b[0;32m    293\u001b[0m                                                      \u001b[0mpos_field\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                                                      schema[ix_schema:])\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\fb.py\u001b[0m in \u001b[0;36mparse_value\u001b[1;34m(encoded_fb, pos, schema)\u001b[0m\n\u001b[0;32m    254\u001b[0m                     \u001b[1;31m# decode field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                     \u001b[0mpos_field\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m                     field_value = FlatBuffer.parse_value(encoded_fb,\n\u001b[0m\u001b[0;32m    257\u001b[0m                                                          \u001b[0mpos_field\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                                                          schema[ix_schema:])\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\fb.py\u001b[0m in \u001b[0;36mparse_value\u001b[1;34m(encoded_fb, pos, schema)\u001b[0m\n\u001b[0;32m    228\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                     \u001b[1;31m# decode element\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                     els.append(FlatBuffer.parse_value(encoded_fb,\n\u001b[0m\u001b[0;32m    231\u001b[0m                                                       \u001b[0mvec_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mel_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                                                       schema[1:]))\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\fb.py\u001b[0m in \u001b[0;36mparse_value\u001b[1;34m(encoded_fb, pos, schema)\u001b[0m\n\u001b[0;32m    254\u001b[0m                     \u001b[1;31m# decode field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                     \u001b[0mpos_field\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m                     field_value = FlatBuffer.parse_value(encoded_fb,\n\u001b[0m\u001b[0;32m    257\u001b[0m                                                          \u001b[0mpos_field\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                                                          schema[ix_schema:])\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tdmclient\\fb.py\u001b[0m in \u001b[0;36mparse_value\u001b[1;34m(encoded_fb, pos, schema)\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[0mstr_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFlatBuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_i32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_fb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mstr_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatBuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_u32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_fb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_fb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstr_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;31m# decode vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 1: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "print('START MOUVEMENT')\n",
    "while True:#(George.get_pos() != George.get_goal()):\n",
    "    \n",
    "    # Read the camera:\n",
    "    ret, frame=VideoCap.read()\n",
    "    \n",
    "    # Get position and angle of the robot: \n",
    "    pos_robot,angle_robot = update(frame, Lausanne.get_pourcentage())\n",
    "    George.set_pos(pos_robot)\n",
    "    George.set_angle(angle_robot)\n",
    "    \n",
    "    # Check if the robot is arrive:\n",
    "    if(current < George.get_path().shape[1]-1):\n",
    "        current = path_update(pos_robot, 3, np.transpose(George.get_path())[current], George.get_current())\n",
    "        George.set_current(current)\n",
    "    else:\n",
    "        print(\"ARRIVED\")\n",
    "        motors(0,0)\n",
    "        break\n",
    "    \n",
    "    # Extract the actual current path goal:\n",
    "    pos_goal =  np.transpose(George.get_path())[current]\n",
    "    \n",
    "    # Do not use the proximity sensor if the robot is nearly arrived:\n",
    "    if current > (George.get_path().shape[0] - thresh_indentation) :\n",
    "        soon_arrived = True\n",
    "        print('soon arrived')\n",
    "        proximity = proxi()\n",
    "    \n",
    "    # Avoid an local obstacle or follow the path:\n",
    "    if move and not (soon_arrived):\n",
    "        speed_l, speed_r, move = avoid_obstacle(prox_horizonta=proximity) \n",
    "    else:\n",
    "        #Thymio is following the optimal path\n",
    "        speed_l, speed_r, old_distance, old_goal  = move_to_position(pos_robot, angle_robot, pos_goal, old_distance, old_angle)\n",
    "\n",
    "        #Thymio is checking if there's an obstacle in front of it\n",
    "        move = check_cars(prox_horizonta=proximity)\n",
    "        print (speed_l, speed_r)\n",
    "       \n",
    "    \n",
    "    # Set motors speeds:\n",
    "    motors(speed_l, speed_r) \n",
    "    \n",
    "    # Desplay everithing\n",
    "    display (frame, 0, 1, 1, 1, path, Lausanne.get_pourcentage())\n",
    "    \n",
    "    # Quit when we press q\n",
    "    keyVal = cv2.waitKey(1) & 0xFF\n",
    "    if keyVal == ord('q'):\n",
    "        motors(0,0)\n",
    "        break\n",
    "     \n",
    "    sleep(0.1)\n",
    "\n",
    "\n",
    "print(\"THE END\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Launch all the code\n",
    "This section allow to lauch all the code in 1 time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. \"Dumb\" Thymio\n",
    "We have implemented this code in another Thymio. The \"Dumb\" Thymio is the robot which will challenge the local avoidance of our main Thymio.\n",
    "\n",
    "In this part, the \"dumb\" Thymio will follow a line until it sees an object in front of it. In this case, it stops (and screams) until the object is removed. We start the robot by pushing on its center button and we stop it the same way. \n",
    "\n",
    "We drew heavily on the code of the exercice of the course from the week 3. The main difference is that we check if we lost the lign to the left or to the right. It allows us to use our \"Dumb\" Thymio in the 2 directions. We saved what was our last turn is the variable \"last turn\" in order to be more efficient to find again the line in case Thymio would lost it because it was going too fast. \n",
    "\n",
    "We have chosen to flash this code into the robot as there was ne need to have communications with the computer for this part. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the \"dumb\" Thymio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_python\n",
    "\n",
    "# Implementation of **Dumb Thymio**\n",
    "# \n",
    "# Author: Alicia Mauroux, Robotic MA1, Fall 2021\n",
    "\n",
    "#constants and variables\n",
    "white = 900\n",
    "GOAL = 100\n",
    "PROX = 2000\n",
    "PROX_SIDE = 1600\n",
    "SOUND = 5\n",
    "\n",
    "lost = False\n",
    "last_turn = False #False = left; True = Right\n",
    "w_le = 0\n",
    "w_ri = 0\n",
    "state = 0\n",
    "\n",
    "timer_period[0] = 100   # 100ms sampling time\n",
    "\n",
    "######################\n",
    "#     FUNCTIONS\n",
    "#####################\n",
    "@onevent\n",
    "def button_center():\n",
    "    \"\"\"\n",
    "    start/stop the robot by pushing on the center button \n",
    "    \n",
    "    global state is the state of our Thymio (1 -> Thymio is running, 0 -> Thymio is sleeping)\n",
    "    \"\"\"\n",
    "    global state\n",
    "    if button_center == 1:\n",
    "        state = 1 if state==0 else 0\n",
    "\n",
    "def ground_white(white_threshold):\n",
    "    \"\"\"\n",
    "    Tests whether the two (or one of the two) ground sensors have seen white\n",
    "    \n",
    "    param white_threshold: threshold starting which it is considered that the sensor saw white\n",
    "    global turn_left means that Thymio is turning left\n",
    "    global lost means that Thymio lost its lign\n",
    "    global w_le is the left prox_ground value\n",
    "    global w_ri is the right prox_ground value\n",
    "    global last_turn indicate which was the last turn of Thymio \n",
    "    \"\"\"\n",
    "    global turn_left, prox_ground_reflected, lost, w_le, w_ri, last_turn\n",
    "    \n",
    "    w_le = prox_ground_reflected[0] \n",
    "    w_ri = prox_ground_reflected[1] \n",
    "    \n",
    "    #white on the left --> turn right then to keep the track\n",
    "    if (w_le > white_threshold):\n",
    "        if (w_ri < white_threshold):\n",
    "            turn_left = False\n",
    "            lost = False\n",
    "            last_turn = True #Last turn was to the right\n",
    "            return True\n",
    "    #white on both direction --> you lost the track! turn back\n",
    "        else:\n",
    "            lost = True\n",
    "            turn_left = False\n",
    "            return True    \n",
    "    else:\n",
    "    #white on the right --> turn left then to keep the track\n",
    "        if(w_ri > white_threshold):\n",
    "            lost = False\n",
    "            turn_left = True\n",
    "            last_turn = False #Last turn was to the left\n",
    "            return True\n",
    "    #following the lign!\n",
    "        else:\n",
    "            lost = False\n",
    "            turn_left = False\n",
    "            return False\n",
    "\n",
    "def test_object(prox_threshold,prox_threshold_side):\n",
    "    \"\"\"\n",
    "    Tests whether the front proximity sensors saw an object on Thymio's way. If there's something, a sound will be played.\n",
    "    \n",
    "    param prox_threshold: threshold starting which it is considered that the sensor saw an object\n",
    "    param prox_threshold_side: threshold starting which it is considered that the side sensor saw an object\n",
    "    \"\"\"\n",
    "    global prox_horizontal\n",
    "    \n",
    "    if (prox_horizontal[2]>prox_threshold):\n",
    "        nf_sound_play(SOUND)\n",
    "        return True\n",
    "    elif (prox_horizontal[1]>prox_threshold_side):\n",
    "        nf_sound_play(SOUND)\n",
    "        return True\n",
    "    elif (prox_horizontal[3]>prox_threshold_side):\n",
    "        nf_sound_play(SOUND)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "def follow_lign(goal):\n",
    "    \"\"\"\n",
    "    Will follow the lign by turning left/right each time the right/left ground sensor is seeing white\n",
    "    \n",
    "    param goal: It's the sensor's value of the black lign that Thymio is following \n",
    "    param prox_threshold_side: threshold starting which it is considered that the side sensor saw an object\n",
    "    global lost: means that Thymio lost its lign\n",
    "    global w_le: is the left prox_ground value\n",
    "    global w_ri: is the right prox_ground value\n",
    "    global last_turn: indicate which was the last turn of Thymio \n",
    "    \"\"\"\n",
    "    global turn_left, lost, last_turn, motor_left_target, motor_right_target\n",
    "    \n",
    "    SPEED0 = 200\n",
    "    SPEED_LOST = SPEED0//2\n",
    "    TURN = 150\n",
    "\n",
    "    if(test_object(PROX,PROX_SIDE)):\n",
    "        l_speed = 0\n",
    "        r_speed = 0\n",
    "    else:\n",
    "        l_speed = SPEED0\n",
    "        r_speed = SPEED0\n",
    "\n",
    "        if (ground_white(white)):\n",
    "            if(turn_left):\n",
    "                l_speed = l_speed - TURN\n",
    "                r_speed = r_speed + TURN\n",
    "            elif(lost):\n",
    "                if(last_turn):\n",
    "                    l_speed = SPEED_LOST\n",
    "                    r_speed = -SPEED_LOST\n",
    "                else:\n",
    "                    l_speed = -SPEED_LOST\n",
    "                    r_speed = SPEED_LOST\n",
    "            else:\n",
    "                l_speed = l_speed  + TURN\n",
    "                r_speed = r_speed - TURN\n",
    "\n",
    "    motor_left_target = l_speed\n",
    "    motor_right_target = r_speed\n",
    "\n",
    "##############################\n",
    "#  MAIN LOOP OF DUMB THYMIO\n",
    "##############################\n",
    "@onevent \n",
    "def timer0():\n",
    "    \n",
    "    global motor_left_target, motor_right_target\n",
    "    \n",
    "    if state:\n",
    "        follow_lign(GOAL)\n",
    "    else:\n",
    "        motor_left_target = 0\n",
    "        motor_right_target = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. few difficulties\n",
    "\n",
    "We had few situation that cause us some trouble.\n",
    "\n",
    "We often had to adapt the extracted color since the light in the room was never the same during different time of the day/night.\n",
    "We had to find a solution for the robot to see the wall when he was avoiding a \"dumb\" robot but not when he was parking.\n",
    "We havn't manage to turn off all the leds of the robot. We have been then obliged to put some paper on the robot to hide the leds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, it was a very nice project and it went well. We were a good team and it was easy to work with each other. With this project, we had a good overview of what we can do in python with a robot like Thymio. \n",
    "To have taken the course of \"Systèmes embarqués et robotique [MICRO-315]\" was very helpful for this project as it was more familiar to us where to search and find the informations we need. The most difficult part was the computer vision as it was new to us. \n",
    "\n",
    "This project show us that the grid approch for path calculation or robot dynamic positioning is not adequate for big map since the cost of calculation is lot's higher than an edge obstacle detection.\n",
    "To improve this project we can improve the way we do the calculation on the grid expension or path calculation with Dijkstra algorithm for exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sources\n",
    "- https://pypi.org/project/tdmclient/ \n",
    "- http://wiki.thymio.org/en:thymioapi\n",
    "- https://stackoverflow.com/questions/2827393/angles-between-two-n-dimensional-vectors-in-python\n",
    "- Exercices from the course (Basics of mobile robotics [MICRO-452])\n",
    "- Control your Thymio in Python\n",
    "- https://github.com/L42Project/Tutoriels/tree/master/Divers/tutoriel36\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
